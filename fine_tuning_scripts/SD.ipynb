{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i00NKbvTIteH"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "YqGyHeHRI0cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes transformers accelerate peft -q\n",
        "pip install --upgrade transformers\n",
        "!pip install git+https://github.com/huggingface/diffusers.git -q\n",
        "pip install --upgrade torch torchvision torchaudio accelerate\n",
        "# Update all related packages to ensure compatibility\n",
        "!pip install --upgrade diffusers transformers accelerate peft"
      ],
      "metadata": {
        "id": "q38G8PahI3_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_dreambooth_lora_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --instance_data_dir=\"/content/drive/MyDrive/dragons/images\" \\\n",
        "  --output_dir=\"/content/dragons_lora\" \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --instance_prompt=\"a detailed YU-GI-Oh dragon monster with intricate artwork\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --snr_gamma=5.0 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --use_8bit_adam \\\n",
        "  --max_train_steps=400 \\\n",
        "  --checkpointing_steps=50 \\\n",
        "  --seed=0"
      ],
      "metadata": {
        "id": "tsNXWHxDJFd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COLAB OPTIMIZED: Bulk YU-GI-OH Dragon Generation (1000 Images)\n",
        "# Run this cell after your LoRA training is complete\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from tqdm.notebook import tqdm  # Colab-optimized progress bar\n",
        "import gc\n",
        "import time\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"üêâ COLAB YU-GI-OH DRAGON BULK GENERATOR\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check GPU and memory\n",
        "print(f\"üñ•Ô∏è GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"/content/dragon_collection_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"üìÅ Output directory: {output_dir}\")\n",
        "\n",
        "# COLAB-OPTIMIZED PIPELINE LOADING\n",
        "print(\"\\nüöÄ Loading pipeline...\")\n",
        "\n",
        "# Check if pipeline already exists in memory (from training)\n",
        "if 'pipe' not in globals():\n",
        "    print(\"Loading fresh pipeline...\")\n",
        "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        torch_dtype=torch.float16,\n",
        "        variant=\"fp16\",\n",
        "        use_safetensors=True\n",
        "    )\n",
        "\n",
        "    # Colab memory optimizations\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_vae_slicing()\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    # Load LoRA\n",
        "    pipe.load_lora_weights(\"/content/dragons_lora\")\n",
        "    print(\"‚úÖ Fresh pipeline loaded with LoRA\")\n",
        "else:\n",
        "    print(\"‚úÖ Using existing pipeline from training\")\n",
        "\n",
        "# YU-GI-OH DRAGON PROMPTS (Colab optimized list)\n",
        "dragon_prompts = [\n",
        "    \"a YU-GI-OH Blue-Eyes White Dragon, majestic pose, trading card art\",\n",
        "    \"a YU-GI-OH Red-Eyes Black Dragon, fierce expression, dark flames\",\n",
        "    \"a YU-GI-OH Cyber Dragon, metallic silver body, mechanical details\",\n",
        "    \"a YU-GI-OH Thunder Dragon, electric energy, storm clouds\",\n",
        "    \"a YU-GI-OH Crystal Dragon, transparent crystalline body, prismatic light\",\n",
        "    \"a YU-GI-OH Shadow Dragon, dark aura, mysterious atmosphere\",\n",
        "    \"a YU-GI-OH Fire Dragon, blazing wings, volcanic background\",\n",
        "    \"a YU-GI-OH Ice Dragon, frozen breath, winter landscape\",\n",
        "    \"a YU-GI-OH Earth Dragon, stone armor, mountain setting\",\n",
        "    \"a YU-GI-OH Wind Dragon, tornado effects, sky background\",\n",
        "    \"a YU-GI-OH Light Dragon, golden radiance, celestial aura\",\n",
        "    \"a YU-GI-OH Dark Dragon, purple energy, nightmare realm\",\n",
        "    \"a YU-GI-OH Machine Dragon, robotic features, cyber world\",\n",
        "    \"a YU-GI-OH Ancient Dragon, mystical symbols, temple ruins\",\n",
        "    \"a YU-GI-OH Elemental Dragon, multi-colored energy, magic circles\"\n",
        "]\n",
        "\n",
        "styles = [\n",
        "    \"official YU-GI-OH card artwork style\",\n",
        "    \"epic and detailed creature design\",\n",
        "\n",
        "]\n",
        "\n",
        "def get_random_prompt():\n",
        "    \"\"\"Generate random YU-GI-OH dragon prompt\"\"\"\n",
        "    base = random.choice(dragon_prompts)\n",
        "    style = random.choice(styles)\n",
        "    return f\"{base}, {style}\"\n",
        "\n",
        "# COLAB-OPTIMIZED GENERATION FUNCTION\n",
        "def generate_dragons_colab(total_count=200, batch_size=10):\n",
        "    \"\"\"\n",
        "    Generate dragons optimized for Colab environment\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüé® Generating {total_count} YU-GI-OH dragon images\")\n",
        "    print(f\"‚ö° Batch size: {batch_size} (optimized for Colab)\")\n",
        "    print(f\"‚è±Ô∏è Estimated time: {total_count * 1.5 / 60:.0f}-{total_count * 2.5 / 60:.0f} minutes\")\n",
        "\n",
        "    # Colab progress bar\n",
        "    progress_bar = tqdm(total=total_count, desc=\"üêâ Dragons Generated\")\n",
        "\n",
        "    generated_count = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    try:\n",
        "        for i in range(0, total_count, batch_size):\n",
        "            batch_count += 1\n",
        "            current_batch_size = min(batch_size, total_count - i)\n",
        "\n",
        "            print(f\"\\nüîÑ Batch {batch_count} ({i+1}-{i+current_batch_size})\")\n",
        "\n",
        "            for j in range(current_batch_size):\n",
        "                img_num = i + j + 1\n",
        "\n",
        "                try:\n",
        "                    # Generate random prompt and seed\n",
        "                    prompt = get_random_prompt()\n",
        "                    seed = random.randint(1, 999999)\n",
        "\n",
        "                    print(prompt)\n",
        "\n",
        "                    # Generate image\n",
        "                    generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "                    result = pipe(\n",
        "                        prompt=prompt,\n",
        "                        negative_prompt=\"blurry, low quality, distorted, deformed, ugly\",\n",
        "                        num_inference_steps=25,  # Balanced speed/quality for bulk generation\n",
        "                        guidance_scale=7.5,\n",
        "                        width=1024,\n",
        "                        height=1024,\n",
        "                        generator=generator\n",
        "                    )\n",
        "\n",
        "                    # Save image\n",
        "                    filename = f\"{file_names[counter]}.png\"\n",
        "                    filepath = os.path.join(output_dir, filename)\n",
        "                    result.images[0].save(filepath)\n",
        "\n",
        "                    generated_count += 1\n",
        "                    counter += 1\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error on image {img_num}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Colab memory management every batch\n",
        "            if batch_count % 3 == 0:  # Every 3 batches\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "                print(f\"üßπ Memory cleanup completed\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\"\\n‚õî Generation stopped by user at {generated_count} images\")\n",
        "\n",
        "    progress_bar.close()\n",
        "    return generated_count\n",
        "\n",
        "# COLAB PREVIEW FUNCTION\n",
        "def show_preview_grid(num_preview=9):\n",
        "    \"\"\"Show a 3x3 grid of generated images in Colab\"\"\"\n",
        "\n",
        "    files = [f for f in os.listdir(output_dir) if f.endswith('.png')]\n",
        "\n",
        "    if len(files) == 0:\n",
        "        print(\"No images found to preview\")\n",
        "        return\n",
        "\n",
        "    # Select random images for preview\n",
        "    preview_files = random.sample(files, min(num_preview, len(files)))\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "    fig.suptitle(\"üêâ Generated YU-GI-OH Dragons Preview\", fontsize=16)\n",
        "\n",
        "    for i, filename in enumerate(preview_files):\n",
        "        row, col = i // 3, i % 3\n",
        "\n",
        "        img_path = os.path.join(output_dir, filename)\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].axis('off')\n",
        "        axes[row, col].set_title(f\"Dragon #{filename[13:17]}\", fontsize=10)\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for i in range(len(preview_files), 9):\n",
        "        row, col = i // 3, i % 3\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# COLAB DOWNLOAD FUNCTION\n",
        "def create_and_download_zip():\n",
        "    \"\"\"Create zip and download in Colab\"\"\"\n",
        "\n",
        "    files = [f for f in os.listdir(output_dir) if f.endswith('.png')]\n",
        "\n",
        "    if len(files) == 0:\n",
        "        print(\"‚ùå No images to zip!\")\n",
        "        return\n",
        "\n",
        "    zip_path = \"/content/yugioh_dragons_collection.zip\"\n",
        "\n",
        "    print(f\"üì¶ Creating zip with {len(files)} images...\")\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:\n",
        "        for filename in tqdm(files, desc=\"Zipping\"):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            zipf.write(file_path, filename)\n",
        "\n",
        "    # Get zip size\n",
        "    zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "    print(f\"‚úÖ Zip created: {zip_size_mb:.1f} MB\")\n",
        "\n",
        "    # Colab download\n",
        "    from google.colab import files\n",
        "    print(\"‚¨áÔ∏è Starting download...\")\n",
        "    files.download(zip_path)\n",
        "\n",
        "    return zip_path\n",
        "\n",
        "# MAIN EXECUTION FOR COLAB\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ READY TO GENERATE!\")\n",
        "print(\"Run the cells below to start generation:\")\n",
        "\n",
        "print(\"\\nüìã STEP 1: Generate Images\")\n",
        "print(\"generated_count = generate_dragons_colab(1000, batch_size=10)\")\n",
        "\n",
        "print(\"\\nüìã STEP 2: Preview Results\")\n",
        "print(\"show_preview_grid()\")\n",
        "\n",
        "print(\"\\nüìã STEP 3: Download Collection\")\n",
        "print(\"create_and_download_zip()\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# AUTO-RUN OPTION (uncomment to run automatically)\n",
        "print(\"üî• AUTO-GENERATION STARTING IN 5 SECONDS...\")\n",
        "print(\"Press Ctrl+C to cancel\")\n",
        "\n",
        "try:\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Start automatic generation\n",
        "    print(\"\\nüé¨ STARTING AUTOMATIC GENERATION\")\n",
        "    generated_count = generate_dragons_colab(1000, batch_siz=10)\n",
        "\n",
        "    print(f\"\\nüéâ GENERATION COMPLETE!\")\n",
        "    print(f\"üìä Successfully generated: {generated_count} images\")\n",
        "\n",
        "    # Show preview\n",
        "    print(\"\\nüñºÔ∏è Showing preview...\")\n",
        "    show_preview_grid()\n",
        "\n",
        "    # Create and download zip\n",
        "    print(\"\\nüì¶ Creating download package...\")\n",
        "    create_and_download_zip()\n",
        "\n",
        "    print(\"\\n‚ú® ALL DONE! Your dragon collection is downloading!\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚õî Auto-generation cancelled\")\n",
        "    print(\"You can run the functions manually:\")\n",
        "    print(\"- generate_dragons_colab(1000)\")\n",
        "    print(\"- show_preview_grid()\")\n",
        "    print(\"- create_and_download_zip()\")"
      ],
      "metadata": {
        "id": "FZxdge__JGO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}